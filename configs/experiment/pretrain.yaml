# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /callbacks: default
  - override /data: protein
  - override /model: diffusion
  - override /trainer: ddp
  

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

callbacks:
  model_checkpoint:
    save_top_k: -1
    every_n_epochs: 5
    save_last: false


data:
  batch_size: 8

model:
  ema_config:
    ema_decay: -1
  optimizer_config:
    lr: 0.0008
    warmup_steps: 7000
    decay_every_n_steps: 20000
    max_steps: 15000000
    adam:
      lr: 0.0008
    af3_lr_scheduler:
      warmup_steps: 7000
      decay_every_n_steps: 20000
      decay_factor: 0.95
      lr: 0.0008
  diffusion_sample: 3
  net:
    transformer:
      n_blocks: 12
      n_heads: 8

trainer:
  # precision: bf16-mixed
  # strategy: deepspeed
  min_epochs: 750
  max_epochs: 1000
  devices: 4
  # gradient_clip_val: 0.5


tags: ["dev"]

task_name: "pretrain"

seed: 42

ckpt_path: data/pretrained_exp_099.pth


