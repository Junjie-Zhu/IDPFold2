# configurations for inference
csv_path: null
plm_emb_dir: null 
nres: [50, 100, 150]
nsamples: 100
max_batch_length: 20000
dt: 0.005
target_pred: v
seed: 42
deterministic: False
logging_dir: "./logs"  # better absolute path, to revise
ckpt_dir: null
ag_dir: null
load_multimer: False

motif_conditioning: False
moe_conditioning: False
self_conditioning: False

sampling:
  sampling_mode: vf  # Options are: vf (plain fow matching) or sc (using score, where parameters below matter)
  sc_scale_noise: 0.0  # scale used to multiply noise if mode == sc
  sc_scale_score: 1.0  # scale used to multiply score if mode == sc, not implemented yet
  gt_mode: "1/t"  # us, tan, or 1/t
  gt_p: 1.0  # float
  gt_clamp_val: null  # 10.0 float or null

schedule:
  schedule_mode: log
  schedule_p: 2.0

guidance_weight: 1.0   # guidance model weights, 1.0 for w/o CFG and autoguidance, 0.0 for excluding the main model. We typically set this value greater than 1

# Autoguidance
autoguidance_ratio: 0.0   # a value between 0 and 1, determining the proportion of autoguidance v.s. classifier-free guidance, 1.0 for all autoguidance, 0.0 for all CFG
autoguidance_ckpt_path: null

model:
  training: False
  token_dim: 768  # dimension of the tokens in the sequence
  nlayers: 10  # number of transformer layers
  nheads: 12  # number of attn heads
  residual_mha: True  # whether to use a residual connection in the mha
  residual_transition: True  # whether to use a residual connection in the transition
  parallel_mha_transition: False  # whether to compute mha and transition as parallel and add them up (AF3 style) or sequentially (normal transofrmers)
  use_attn_pair_bias: True  # whether to bias attention using a bias coming from a pair representation

  strict_feats: False  # if False, then fills missing features with default values (e.g. chain break with zero, residue sequence index by [0, 1, 2, ...], etc)
  # If True, if some feature is not provided, then it raises an error

  feats_init_seq: ["plm_emb", "res_type", "res_idx", "chain_break_per_res"]  # Sequence features to include in initial representation
  feats_cond_seq: ["time_emb"]  # Sequence features to include in conditioning variables

  # Parameters for the features we extract (both for sequence representatoin and conditioning vector)
  t_emb_dim: 256  # dimension of the time embedding
  idx_emb_dim: 128  # dimension of the residue index embedding
  dim_cond: 512  # dimension of conditioning vector
  plm_in_dim: 1280
  plm_out_dim: 256

  feats_pair_repr: ["xt_pair_dists", "rel_pos"]  # Features to include in the pair representation
  feats_pair_cond: ["time_emb"]  # Features to include in the pair representation conditioning

  # Parameters for the pair features we extract
  # Binning for the pair distances of noisy xt
  xt_pair_dist_dim: 64
  xt_pair_dist_min: 0.1  # in nm (not ?)
  xt_pair_dist_max: 3  # in nm (not ?)
  r_max: 32  # maximum relative position (in sequence index) to consider

  # Dimension of final pair representation
  pair_repr_dim: 512
  num_registers: 10
  use_qkln: True

  use_moe: True
  n_experts: 5
  n_activated_experts: 2
  dim_moe_cond: 0
  capacity_factor: 1.3
  normalize_expert_weights: True

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  run:
    dir: .
  output_subdir: null

